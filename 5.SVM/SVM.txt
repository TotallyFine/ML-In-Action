1 SVM是什么？
  Support Vector Machines支持向量机，可以用来分类、回归、离群点检测。在将数据输入到SVM分类器之前最好进行标准化。并且二分类问题中将标签变为-1 +1
2 SVM的优缺点有哪些？
  优点：在高维空间有效，当样本空间的维度比样本树高是仍然有效，在预测的时候只需要支持向量，内存效率高，SVM可以通过指定不同的核函数来完成不同的任务。缺点：当特征维度远远岛屿训练样本树的时候表现可能不好，SVM不直接提供概率估计，可以通过5折交叉验证计算得到但是开销较大。
3 SVM如何实现一对多分类？
  可以对每个类别训练一个模型也就是one vs rest，来判断每个数据是不是这个类别的，只需要训练n_class个模型。或者每两个类别训练一个分类器one vs one，需要训练n_class*(n_class-1)/2个分类器。
4 如何用SVM实现回归？
  这个比较复杂。参见https://blog.csdn.net/u013395544/article/details/79229703 http://blog.sina.com.cn/s/blog_62970c250102xfzj.html
5 Novelty and Outlier Detection是什么？
  novelty detection是先给定正常数据集，然后判断新的数据是否是正常的。outlier detection是给定的训练数据集中包括不正常的，需要发展这些不正常/离群点。novelty detection可以使用One Class SVM实现，它不需要标注，通常是用RBF核实现。outlier detection可以通过协方差估计中对高斯分布数据集的离群值检验方法等其他方法实现。
6 SVM中的参数有哪些？
  在训练RBF核的SVM的时候有两个参数 C gamma，C的值越大分类器越倾向于分类准确越可能过拟合，C的值越小分类的平面越倾向于平滑，其他核中也有C这个参数。默认情况下C是1，当数据中噪声越大的时候应该降低C。gamma决定了单个的数据有多大的影响力，gamma的值越低影响力越大，gamma 的值越大影响力越小，影响力指的是辐射到其他地方的范围。
7 SVM如何处理类别不平衡问题？
  两个方法：设置类别权重、调整参数C。在fit方法中设置不同类别的权重正浮点数数，可以有效降低测试误差，也可以使用class_weight='balanced'让学习器统计数据来设置权重。