1 什么是CART算法？
  CART Classification And Regression Trees分类回归树，该算法可以用来回归和分类。决策树实际上就是一种贪心算法，在给定时间内作出最佳选择而不关心全局的是否最优。在ID3算法中每次选取当前最佳的特征来进行分类，这个特征使用完之后就不再考虑。而CART则使用二元切分法：每次把数据分成两份，如果数据的某特征值等于切分所要求的值就进入左子树，反之进入右子树。
2 在机器学习中人们说的方差和偏差是什么？
  方差是不同模型之间的差别，而偏差是模型和实际值之间的差别。除了偏差，还有系统性误差如测量误差。
3 CART算法处理什么样的数据？它使用什么方法来度量香农熵？
  ID3处理离散性数据，因此连续型数据需要离散话这样会破坏连续变量的内在性质。CART则可以处理连续性的数据。在CART中先计算数据的均值，然后每个数据减去均值的平方之和来评价连续型数据的混乱度。总方差可以通过均方差乘以数据集中的样本个数来得到。
4 在CART算法中过拟合会出现什么现象？如何处理？
  当叶子结点过多时可以认为发生了过拟合。两种方法处理：1 预剪枝 2 后剪枝。预剪枝：在选择最好的特征和阈值的时候有两个参数，分别是允许的最小划分后的数据集的大小、允许的划分后的最小混乱度的降低数，通过控制这两个参数可以实现对叶子结点数目的控制。后剪枝：将数据分为训练集和测试集，首先指定参数使得构建出的树足够复杂，便于剪枝。接下来从上而下找到叶结点，用测试集来判断将这些结点合并能否降低测试误差，如果是的话就合并。
5 什么是分段线性？什么是模型树？什么是回归树？
  分段线性 piecewise linear值得是模型有多个线性片段组成，当数据处于不同区域的时候用不同的线性函数进行拟合，而将数据划分开就使用树。若叶节点使用的模型是分段常数则称为回归树，若叶节点使用的模型是线性回归则称为模型树。
6 树回归和标准回归比较？
  树回归在预测复杂数据时会比简单的线性模型更有效。