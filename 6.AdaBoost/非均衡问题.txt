在大多数情况下不同类别的分类代价并不相等。因此需要不同的指标来评价分类的效果。
评价分类器的指标：
1 错误率：所有测试样例中错分的比例。但是这样的度量掩盖了样例如何被分错的事实。
2 混淆矩阵：
给出一个三分类的例子
                    预测结果
              类别1  类别2  类别3
         类别1 24      2      5
真实结果 类别2 2       27     0
         类别3 4       3      30

如果在混淆矩阵中所有非对角矩阵的数值都为0则是一个完美的矩阵。
一个二分类的问题中
                    预测结果
                   +1         -1
         +1     真正例TP    伪反例FN
真实结果 -1     伪正例FP    正反例TN

3 正确率Precision：TP/(TP+FP)预测为正例中的真正例的占比，只要控制阈值使得更严格即可提高正确率，但会漏掉其他的正例。提高正确率会导致把好人认成坏人。
4 召回率Recall：TP/(TP+FN)预测为正例在所有正例中的占比，只要放松阈值就可以增加召回率，但是会把很多假的认为是真的。提高召回率就会导致滥竽充数。
5 ROC曲线：
    X轴是假阳率=FP/(FP+TN) Y轴是真阳率=TP/(TP+FN)。ROC曲线给出的是当阈值变化时假阳率和真阳率的变化情况。左下角的点对应的是将所有样例判为反例的情况，右上角是将所有样例判为正例的情况。
    曲线变化的含义：从左下角到右上角是一个阈值逐渐放松的过程，在此过程中会将正确的样例预测为错误这种情况减少，但是将错误预测为正确这种情况增加。
    由于在不同的阈值下不同的分类器的表现情况可能不一样，因此以某种方式将他们组合起来或许会更有意义。
    在理想的情况下，最佳分类器应尽可能处于左上角，意味着在假阳率很低的情况下获得了很高的真阳率。
    为了计算ROC曲线每个分类器都要提供“阈值”：在朴素贝叶斯中是可能性，在Logisitic中是输入到Sigmoid中的参数，在AdaBoost和SVM中是输入到sign的参数，这些数值都可以作为绘制ROC时的阈值。
6 AUC：ROC曲线下面积，随机猜测的面积是0.5，AUC给出的是分类器的平均性能，并不能完全代替对整条曲线的观察。

7 什么是代价敏感学习？
  真正例、伪反例、伪正例、正反例具有不同的代价，训练完后通过计算不同阈值下的
  代价来选择代价最小的分类器
8 如何处理类别数据非均衡方法？
  欠采样、过采样、代价敏感学习。